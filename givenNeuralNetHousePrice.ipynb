{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4712</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10659</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9786</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6762</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>206000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0       1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1       2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2       3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3       4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4       5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "..    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "995   996          50       RL         51.0     4712   Pave   NaN      IR1   \n",
       "996   997          20       RL          NaN    10659   Pave   NaN      IR1   \n",
       "997   998          20       RL          NaN    11717   Pave   NaN      IR1   \n",
       "998   999          30       RM         60.0     9786   Pave   NaN      Reg   \n",
       "999  1000          20       RL         64.0     6762   Pave   NaN      Reg   \n",
       "\n",
       "    LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "..          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "995         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "996         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "997         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "998         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "999         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0        2   2008        WD         Normal     208500  \n",
       "1        5   2007        WD         Normal     181500  \n",
       "2        9   2008        WD         Normal     223500  \n",
       "3        2   2006        WD        Abnorml     140000  \n",
       "4       12   2008        WD         Normal     250000  \n",
       "..     ...    ...       ...            ...        ...  \n",
       "995      8   2006        WD        Abnorml     121600  \n",
       "996      1   2006       COD         Normal     136500  \n",
       "997      2   2009        WD         Normal     185000  \n",
       "998      5   2006        WD         Normal      91000  \n",
       "999      2   2010        WD         Normal     206000  \n",
       "\n",
       "[1000 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "# Select only numeric columns that have no missing data.\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "clean_numeric_cols = [col for col in numeric_cols if data[col].isna().sum() == 0]\n",
    "data_clean = data[clean_numeric_cols]\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 4 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalesPrice'\n",
    "top4_features = target_corr.head(4).index\n",
    "print(\"Selected top 4 features:\", list(top4_features))\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top4_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. Define the Neural Network Model\n",
    "# -----------------------------\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output layer for regression\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HousePriceModel(input_dim=X_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 41016694210.5600\n",
      "Epoch [20/1000], Loss: 40529082286.0800\n",
      "Epoch [30/1000], Loss: 39173803458.5600\n",
      "Epoch [40/1000], Loss: 36733225123.8400\n",
      "Epoch [50/1000], Loss: 33185796259.8400\n",
      "Epoch [60/1000], Loss: 28752210739.2000\n",
      "Epoch [70/1000], Loss: 23805064888.3200\n",
      "Epoch [80/1000], Loss: 18832757719.0400\n",
      "Epoch [90/1000], Loss: 14341794078.7200\n",
      "Epoch [100/1000], Loss: 10739711672.3200\n",
      "Epoch [110/1000], Loss: 8216096808.9600\n",
      "Epoch [120/1000], Loss: 6668614656.0000\n",
      "Epoch [130/1000], Loss: 5799483320.3200\n",
      "Epoch [140/1000], Loss: 5293045329.9200\n",
      "Epoch [150/1000], Loss: 4930773411.8400\n",
      "Epoch [160/1000], Loss: 4617143234.5600\n",
      "Epoch [170/1000], Loss: 4320380170.2400\n",
      "Epoch [180/1000], Loss: 4036166973.4400\n",
      "Epoch [190/1000], Loss: 3758260797.4400\n",
      "Epoch [200/1000], Loss: 3492902789.1200\n",
      "Epoch [210/1000], Loss: 3239803156.4800\n",
      "Epoch [220/1000], Loss: 3002119116.8000\n",
      "Epoch [230/1000], Loss: 2779051571.2000\n",
      "Epoch [240/1000], Loss: 2575318471.6800\n",
      "Epoch [250/1000], Loss: 2393487063.0400\n",
      "Epoch [260/1000], Loss: 2232407482.8800\n",
      "Epoch [270/1000], Loss: 2094945984.0000\n",
      "Epoch [280/1000], Loss: 1980009866.2400\n",
      "Epoch [290/1000], Loss: 1887449973.7600\n",
      "Epoch [300/1000], Loss: 1816400394.2400\n",
      "Epoch [310/1000], Loss: 1760237248.0000\n",
      "Epoch [320/1000], Loss: 1719170265.6000\n",
      "Epoch [330/1000], Loss: 1688369858.5600\n",
      "Epoch [340/1000], Loss: 1662895636.4800\n",
      "Epoch [350/1000], Loss: 1644388752.6400\n",
      "Epoch [360/1000], Loss: 1627636316.1600\n",
      "Epoch [370/1000], Loss: 1614083991.0400\n",
      "Epoch [380/1000], Loss: 1602812641.2800\n",
      "Epoch [390/1000], Loss: 1592980405.7600\n",
      "Epoch [400/1000], Loss: 1583877719.0400\n",
      "Epoch [410/1000], Loss: 1574391642.8800\n",
      "Epoch [420/1000], Loss: 1564321675.5200\n",
      "Epoch [430/1000], Loss: 1557419297.2800\n",
      "Epoch [440/1000], Loss: 1549176067.8400\n",
      "Epoch [450/1000], Loss: 1541282713.6000\n",
      "Epoch [460/1000], Loss: 1532642810.8800\n",
      "Epoch [470/1000], Loss: 1525259454.7200\n",
      "Epoch [480/1000], Loss: 1518617868.8000\n",
      "Epoch [490/1000], Loss: 1512405634.5600\n",
      "Epoch [500/1000], Loss: 1506313757.4400\n",
      "Epoch [510/1000], Loss: 1499878494.7200\n",
      "Epoch [520/1000], Loss: 1494345822.7200\n",
      "Epoch [530/1000], Loss: 1490016289.2800\n",
      "Epoch [540/1000], Loss: 1483659819.5200\n",
      "Epoch [550/1000], Loss: 1478786753.2800\n",
      "Epoch [560/1000], Loss: 1474081402.8800\n",
      "Epoch [570/1000], Loss: 1470073689.6000\n",
      "Epoch [580/1000], Loss: 1465747678.7200\n",
      "Epoch [590/1000], Loss: 1462246183.6800\n",
      "Epoch [600/1000], Loss: 1459333373.4400\n",
      "Epoch [610/1000], Loss: 1455390192.6400\n",
      "Epoch [620/1000], Loss: 1451874209.2800\n",
      "Epoch [630/1000], Loss: 1449684922.8800\n",
      "Epoch [640/1000], Loss: 1447065090.5600\n",
      "Epoch [650/1000], Loss: 1442949536.0000\n",
      "Epoch [660/1000], Loss: 1440358147.8400\n",
      "Epoch [670/1000], Loss: 1437850526.7200\n",
      "Epoch [680/1000], Loss: 1435554813.4400\n",
      "Epoch [690/1000], Loss: 1433665672.9600\n",
      "Epoch [700/1000], Loss: 1431090698.2400\n",
      "Epoch [710/1000], Loss: 1428672087.0400\n",
      "Epoch [720/1000], Loss: 1427523589.1200\n",
      "Epoch [730/1000], Loss: 1424642279.6800\n",
      "Epoch [740/1000], Loss: 1424355389.4400\n",
      "Epoch [750/1000], Loss: 1420967805.4400\n",
      "Epoch [760/1000], Loss: 1418753167.3600\n",
      "Epoch [770/1000], Loss: 1416962775.0400\n",
      "Epoch [780/1000], Loss: 1416813683.2000\n",
      "Epoch [790/1000], Loss: 1414763942.4000\n",
      "Epoch [800/1000], Loss: 1412340979.2000\n",
      "Epoch [810/1000], Loss: 1411110919.6800\n",
      "Epoch [820/1000], Loss: 1409829972.4800\n",
      "Epoch [830/1000], Loss: 1407886382.0800\n",
      "Epoch [840/1000], Loss: 1406405574.4000\n",
      "Epoch [850/1000], Loss: 1405662179.8400\n",
      "Epoch [860/1000], Loss: 1404104633.6000\n",
      "Epoch [870/1000], Loss: 1402924019.2000\n",
      "Epoch [880/1000], Loss: 1401560478.7200\n",
      "Epoch [890/1000], Loss: 1400742287.3600\n",
      "Epoch [900/1000], Loss: 1399989908.4800\n",
      "Epoch [910/1000], Loss: 1400096186.8800\n",
      "Epoch [920/1000], Loss: 1398395343.3600\n",
      "Epoch [930/1000], Loss: 1397315246.0800\n",
      "Epoch [940/1000], Loss: 1397130060.8000\n",
      "Epoch [950/1000], Loss: 1395159896.3200\n",
      "Epoch [960/1000], Loss: 1394698813.4400\n",
      "Epoch [970/1000], Loss: 1393980661.7600\n",
      "Epoch [980/1000], Loss: 1393415016.9600\n",
      "Epoch [990/1000], Loss: 1393444247.0400\n",
      "Epoch [1000/1000], Loss: 1391597416.9600\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 939191040.0\n",
      "Test MSE (scikit-learn): 939191040.0\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)\n",
    "# Test Mean Squared Error: 935741376.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
